{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Unnamed: 0  speed  dist\n0           1      4     2\n1           2      4    10",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>speed</th>\n      <th>dist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data/cars_data.csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0xaed0a48>"
     },
     "metadata": {},
     "execution_count": 3
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 388.965625 262.19625\" width=\"388.965625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M -0 262.19625 \r\nL 388.965625 262.19625 \r\nL 388.965625 0 \r\nL -0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 46.965625 224.64 \r\nL 381.765625 224.64 \r\nL 381.765625 7.2 \r\nL 46.965625 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"PathCollection_1\">\r\n    <defs>\r\n     <path d=\"M 0 3 \r\nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \r\nC 2.683901 1.55874 3 0.795609 3 0 \r\nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \r\nC 1.55874 -2.683901 0.795609 -3 0 -3 \r\nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \r\nC -2.683901 -1.55874 -3 -0.795609 -3 0 \r\nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \r\nC -1.55874 2.683901 -0.795609 3 0 3 \r\nz\r\n\" id=\"m0ac9113217\" style=\"stroke:#ffffff;stroke-width:0.75;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#p21bae75cc1)\">\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"62.32653\" xlink:href=\"#m0ac9113217\" y=\"214.730946\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"62.32653\" xlink:href=\"#m0ac9113217\" y=\"201.332852\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"105.766271\" xlink:href=\"#m0ac9113217\" y=\"211.381423\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"105.766271\" xlink:href=\"#m0ac9113217\" y=\"181.23571\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"120.246185\" xlink:href=\"#m0ac9113217\" y=\"191.284281\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"134.726099\" xlink:href=\"#m0ac9113217\" y=\"201.332852\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"149.206013\" xlink:href=\"#m0ac9113217\" y=\"187.934758\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"149.206013\" xlink:href=\"#m0ac9113217\" y=\"174.536663\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"149.206013\" xlink:href=\"#m0ac9113217\" y=\"161.138569\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"163.685927\" xlink:href=\"#m0ac9113217\" y=\"189.609519\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"163.685927\" xlink:href=\"#m0ac9113217\" y=\"171.18714\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"178.16584\" xlink:href=\"#m0ac9113217\" y=\"194.633805\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"178.16584\" xlink:href=\"#m0ac9113217\" y=\"184.585234\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"178.16584\" xlink:href=\"#m0ac9113217\" y=\"177.886187\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"178.16584\" xlink:href=\"#m0ac9113217\" y=\"171.18714\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"192.645754\" xlink:href=\"#m0ac9113217\" y=\"174.536663\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"192.645754\" xlink:href=\"#m0ac9113217\" y=\"161.138569\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"192.645754\" xlink:href=\"#m0ac9113217\" y=\"161.138569\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"192.645754\" xlink:href=\"#m0ac9113217\" y=\"141.041427\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"207.125668\" xlink:href=\"#m0ac9113217\" y=\"174.536663\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"207.125668\" xlink:href=\"#m0ac9113217\" y=\"157.789045\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"207.125668\" xlink:href=\"#m0ac9113217\" y=\"117.594762\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"207.125668\" xlink:href=\"#m0ac9113217\" y=\"84.099526\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"221.605582\" xlink:href=\"#m0ac9113217\" y=\"184.585234\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"221.605582\" xlink:href=\"#m0ac9113217\" y=\"174.536663\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"221.605582\" xlink:href=\"#m0ac9113217\" y=\"127.643333\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"236.085496\" xlink:href=\"#m0ac9113217\" y=\"164.488092\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"236.085496\" xlink:href=\"#m0ac9113217\" y=\"151.089998\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"250.56541\" xlink:href=\"#m0ac9113217\" y=\"164.488092\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"250.56541\" xlink:href=\"#m0ac9113217\" y=\"151.089998\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"250.56541\" xlink:href=\"#m0ac9113217\" y=\"134.34238\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"265.045323\" xlink:href=\"#m0ac9113217\" y=\"147.740474\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"265.045323\" xlink:href=\"#m0ac9113217\" y=\"124.293809\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"265.045323\" xlink:href=\"#m0ac9113217\" y=\"90.798573\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"265.045323\" xlink:href=\"#m0ac9113217\" y=\"77.400479\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"279.525237\" xlink:href=\"#m0ac9113217\" y=\"157.789045\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"279.525237\" xlink:href=\"#m0ac9113217\" y=\"141.041427\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"279.525237\" xlink:href=\"#m0ac9113217\" y=\"104.196667\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"294.005151\" xlink:href=\"#m0ac9113217\" y=\"164.488092\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"294.005151\" xlink:href=\"#m0ac9113217\" y=\"137.691903\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"294.005151\" xlink:href=\"#m0ac9113217\" y=\"130.992856\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"294.005151\" xlink:href=\"#m0ac9113217\" y=\"124.293809\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"294.005151\" xlink:href=\"#m0ac9113217\" y=\"110.895715\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"322.964979\" xlink:href=\"#m0ac9113217\" y=\"107.546191\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"337.444892\" xlink:href=\"#m0ac9113217\" y=\"127.643333\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"351.924806\" xlink:href=\"#m0ac9113217\" y=\"100.847144\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"351.924806\" xlink:href=\"#m0ac9113217\" y=\"64.002384\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"351.924806\" xlink:href=\"#m0ac9113217\" y=\"62.327622\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"351.924806\" xlink:href=\"#m0ac9113217\" y=\"17.109054\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#ffffff;stroke-width:0.75;\" x=\"366.40472\" xlink:href=\"#m0ac9113217\" y=\"75.725717\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m19d8e8c397\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"76.806444\" xlink:href=\"#m19d8e8c397\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(73.625194 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"149.206013\" xlink:href=\"#m19d8e8c397\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(142.843513 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"221.605582\" xlink:href=\"#m19d8e8c397\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(215.243082 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"294.005151\" xlink:href=\"#m19d8e8c397\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(287.642651 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"366.40472\" xlink:href=\"#m19d8e8c397\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(360.04222 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_6\">\r\n     <!-- speed -->\r\n     <defs>\r\n      <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n      <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n     </defs>\r\n     <g transform=\"translate(199.259375 252.916562)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"52.099609\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"115.576172\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"177.099609\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"238.623047\" xlink:href=\"#DejaVuSans-100\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_6\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mdcae8514d2\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#mdcae8514d2\" y=\"218.08047\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(33.603125 221.879689)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#mdcae8514d2\" y=\"184.585234\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(27.240625 188.384453)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#mdcae8514d2\" y=\"151.089998\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 40 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(27.240625 154.889217)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#mdcae8514d2\" y=\"117.594762\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 60 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(27.240625 121.393981)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#mdcae8514d2\" y=\"84.099526\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 80 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(27.240625 87.898744)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#mdcae8514d2\" y=\"50.60429\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 100 -->\r\n      <g transform=\"translate(20.878125 54.403508)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#mdcae8514d2\" y=\"17.109054\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 120 -->\r\n      <g transform=\"translate(20.878125 20.908272)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_14\">\r\n     <!-- dist -->\r\n     <defs>\r\n      <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n      <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n     </defs>\r\n     <g transform=\"translate(14.798438 125.048125)rotate(-90)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"91.259766\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"143.359375\" xlink:href=\"#DejaVuSans-116\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 46.965625 224.64 \r\nL 46.965625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 381.765625 224.64 \r\nL 381.765625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 46.965625 224.64 \r\nL 381.765625 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 46.965625 7.2 \r\nL 381.765625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p21bae75cc1\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"46.965625\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "x = data['speed'] \n",
    "y = data['dist']\n",
    "sns.scatterplot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.651\nModel:                            OLS   Adj. R-squared:                  0.644\nMethod:                 Least Squares   F-statistic:                     89.57\nDate:                Fri, 19 Jun 2020   Prob (F-statistic):           1.49e-12\nTime:                        09:00:11   Log-Likelihood:                -206.58\nNo. Observations:                  50   AIC:                             417.2\nDf Residuals:                      48   BIC:                             421.0\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept    -17.5791      6.758     -2.601      0.012     -31.168      -3.990\nx              3.9324      0.416      9.464      0.000       3.097       4.768\n==============================================================================\nOmnibus:                        8.975   Durbin-Watson:                   1.676\nProb(Omnibus):                  0.011   Jarque-Bera (JB):                8.189\nSkew:                           0.885   Prob(JB):                       0.0167\nKurtosis:                       3.893   Cond. No.                         50.7\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# df = pd.DataFrame(list(zip(x, y)), columns =['x', 'y'])\n",
    "ols = sm.OLS.from_formula('y~x', data)\n",
    "ols_result = ols.fit()\n",
    "print(ols_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 and Adjusted R2\n",
    "### Dergree of Freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degree of Freedom refers to the number of observations free to vary while estimating the parameters. The number of independent data that you can use to estimate the parameter.\n",
    "\n",
    "Ex : Suppose u have a list = [1, 4, x, 5] and the mean of the list is 5. Then we can estimate the x. As 15 + x = 4*5. The value X has no option to vary and it cant take any other value. After estimating the mean, we have only n - 1 dof (independent pieces of information).\n",
    "\n",
    "DoF in Regression :       \n",
    "1. In regression, the DoF is n - k (k is number of coefficients including the intercept). The degrees of freedom are the independent pieces of information that are available for estimating your coefficients. For precise coefficient estimates and powerful hypothesis tests in regression, you must have many error degrees of freedom, which equates to having many observations for each model term.    \n",
    "2. As you add terms to the model, the error degrees of freedom decreases. You have fewer pieces of information available to estimate the coefficients. This situation reduces the precision of the estimates and the power of the tests. When you have too few remaining degrees of freedom, you can’t trust the regression results. If you use all your degrees of freedom, the procedure can’t calculate the p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R2**:   \n",
    "1. The R-Squared Statistic provides a proportion measure and is independent of the scale of Y. R squared measures the proportion of variability in Y that can be explained using X. This statistic has an advantage that it puts up values between 0 and 1.    \n",
    "2. Without any predictors, you have the basic prediction of mean of Y (where the variablity in prediction is limited). By adding Xs, our prediction capability increases and eventually the vairability explained in prediction Y increases. That is R2.  \n",
    "$$ R^2 = 1 - \\frac{Residuals Sum of Squares}{Total Sum of Squares}$$\n",
    "$$ R^2 = 1 - \\frac{\\sum (y - \\hat y)^2} {\\sum (y - \\bar y)^2}$$     \n",
    "3. The numerator explains the error reduced with adding predictors. Denominator error would be big as it doesnt build any predictor.    \n",
    "4. **__Beware values are sum of squares and not RMSE or MSE__**      \n",
    "\n",
    "The \"Proportion of variance explained (R2)'' indicates how much better the function predicts the dependent variable than just using the mean value of the dependent variable.  This is also known as the \"coefficient of multiple determination.''  It is computed as follows: Suppose that we did not fit an equation to the data and ignored all information about the independent variables in each observation.  Then, the best prediction for the dependent variable value for any observation would be the mean value of the dependent variable over all observations.  The \"variance'' is the sum of the squared differences between the mean value and the value of the dependent variable for each observation.  Now, if we use our fitted function to predict the value of the dependent variable, rather than using the mean value, a second kind of variance can be computed by taking the sum of the squared difference between the value of the dependent variable predicted by the function and the actual value.  Hopefully, the variance computed by using the values predicted by the function is better (i.e., a smaller value) than the variance computed using the mean value.  The \"Proportion of variance explained'' is computed as 1 – (variance using predicted value / variance using mean).  If the function perfectly predicts the observed data, the value of this statistic will be 1.00 (100%).  If the function does no better a job of predicting the dependent variable than using the mean, the value will be 0.00. \n",
    "\n",
    "   \n",
    "**Adjusted R2**:   \n",
    "1. Mainly to penalize the addition of variables in regression\n",
    "$$ AdjustedR^2 = 1 - \\frac{\\frac{\\sum (y - \\hat y)^2}{n - k - 1}} {\\frac{\\sum (y - \\bar y)^2}{n - 1}}$$     \n",
    "2. The derivation is intuitive. If you look into numerator which is sse with predictors the dof is (n - k - 1). As there is a target variables while calculating sse. Similarly the dof when building only with ymean is (n - 1), as k = 0 (no predictors).             \n",
    "3. Think of dof as :  number of equations and number of variables. In our example of 50 observations, it is difficult to get close form solution with 2 variables(m, c). Ideally we would want 50 Xs. In the same manner, while predicting sse with Xs, the dof freedom is (n - k - 1), where the -1 is for intercept. Dof with ymean is N-1, where the -1 is the constant ymean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "r2 : 0.651\nAdjustedr2 :  0.644\n"
    }
   ],
   "source": [
    "# R2 & Adjusted R2\n",
    "c, m  = ols_result.params.values\n",
    "ypred = m*data['speed'] + c\n",
    "sse = np.sum((y - ypred)**2)   ## Error with X\n",
    "sst = np.sum((y - np.mean(y))**2)   ## Error without X; basically with just ymean \n",
    "r2 = round(1 - sse/sst, 3)\n",
    "print(f\"r2 : {r2}\")\n",
    "\n",
    "# Adjusted R2\n",
    "n = data.shape[0]\n",
    "k = 1\n",
    "adj_r2 = round(1 - (sse/(n-k-1))/(sst/(n-1)),3)\n",
    "print(f\"Adjustedr2 :  {adj_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual  Standard Error (RSE) of estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "1. Residual Standard Error is measure of the quality of a linear regression fit. Theoretically, every linear model is assumed to contain an error term E. Due to the presence of this error term, we are not capable of perfectly predicting our response variable (dist) from the predictor (speed) one. The Residual Standard Error is the average amount that the response (dist) will deviate from the true regression line. In our example, the actual distance required to stop can deviate from the true regression line by approximately 15.3795867 feet, on average. In other words, given that the mean distance for all cars to stop is 42.98 and that the Residual Standard Error is 15.3795867, we can say that the percentage error is (any prediction would still be off by) 35.78%. It’s also worth noting that the Residual Standard Error was calculated with 48 degrees of freedom. Simplistically, degrees of freedom are the number of data points that went into the estimation of the parameters used after taking into account these parameters (restriction). In our case, we had 50 data points and two parameters (intercept and slope).    \n",
    "2. Residual Standard Error is an estimate of the standard deviation of the error associated with each prediction term. It is the average amount that the response will deviate from the true regression line. The RSE is considered as a measure of the lack of fit. It provides an absolute measure for this in terms of Y’s unit.   \n",
    "3. When the residual standard error is exactly 0 then the model fits the data perfectly (likely due to overfitting).   \n",
    "4. RSE is in the same units as the target. So it gives clear indication of how much the deviation is. But R2 is unit independent and is always between 0-1  \n",
    "$$ RSE = \\sqrt {\\frac {(y - \\hat y)^2} {N - 2}}$$     \n",
    "5. In general,  $$ RSE = \\sqrt {\\frac {(y - \\hat y)^2} {N - k - 1}}$$    \n",
    "6. Models with more variables can have high RSE if there is not much decrease in RSS. \n",
    "\n",
    "![alt text](Images\\RSE_R2.png \"RSE_R2\")\n",
    "\n",
    "The difference between the RSE and the R2 is that the RSE tells you something about the inaccuracy of the model (in this case the regression line) given the observed data. The R2 on the other hand tells you how much variation is explained by the model (i.e. the regression line) relative the variation that was explained by the mean alone (i.e. the simplest model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RSE : 15.38\n"
    }
   ],
   "source": [
    "## RSE\n",
    "c, m = ols_result.params.values\n",
    "y_pred = m*x + c\n",
    "error_sq = np.square(y - y_pred)\n",
    "rse = round(np.sqrt(np.sum(error_sq)/(len(x)-2)), 2)\n",
    "print(f\"RSE : {rse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIC BIC Log-Likelihood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__**AIC BIC Log-Likelihood**__    \n",
    "\n",
    "1. They are methods used for model selection. A common approach would be to choose model which performs better in kfold cross validation. But AIC, BIC provides an alternate approach which looks not only at model performance but also at model complexity.    \n",
    "2. The benefit of these information criterion statistics is that they do not require a hold-out test set, although a limitation is that they do not take the uncertainty of the models into account and may end-up selecting models that are too simple. The AIC/BIC can give high penalty and can make us choose simpler model.\n",
    "3. These methods fall under probabilistic model selection (bcos it uses log-Likelihood).     \n",
    "    Model Performance : Log- likelihood (mse)     \n",
    "    Model Complexity : Interms of number of degrees of freedom/parameters in model\n",
    "4. Log-Likelihood: It is derived from Max Likelihood.     \n",
    "    Max Likelihood Estimate = P(X : theta) ie, maximise the conditional probability of observing X given the parameters theta.      \n",
    "    The above eq can be expanded as P(x1, x2,..xn : theta). The joint prob can be restated as the multiplication of conditional prob of each example.         \n",
    "    It can also be written as summation (log(P(xi : theta)))        \n",
    "    It is mostly the MSE or Log-loss for regression & classification prob respectively.         \n",
    "5. Akaike Information Criteria:\n",
    "    Method of selecting and scoring a models\n",
    "    $$ AIC = -2*loglikelihood + 2*k $$\n",
    "    k = number of parameters in model (including intercept). Choose model with lowest AIC.\n",
    "6. Bayesian Information Criteria:\n",
    "    $$ BIC = -2*loglikelihood + log(N)*k $$\n",
    "    where N is number of examples. Log is natural log with base-e. \n",
    "    The BIC penalizes the model more and thus it chooses simpler model compared to AIC based model.\n",
    "\n",
    "\n",
    "_**Note**_:\n",
    "1. Not able to correcly calculate the likelihood data as -206.58?    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Likelihood & Maximum Likelihood        \n",
    "1. Maximum likelihood estimation(MLE) is a popular mechanism which is used to estimate the model parameters of a regression model    \n",
    "2. In general, it can be used to estimate parameters in any distributions. (Guassian, Binomial, etc). In real life scenarios, the mean and std dev are unknown and needs to be estimated from data. MLE helps to estimate the parameters that best describes the given data.     \n",
    "3. Given a sample [1, 2, 3, 4]. You could probably estimate the mean & std dev straight away(mean = 2.5, std dev = 1). But they are a good representation of given data but may not best to describe the population.     \n",
    "4. MLE can be defined as a method for estimating population parameters (such as the mean and variance for Normal, rate (lambda) for Poisson, etc.) from sample data such that the probability (likelihood) of obtaining the observed data is maximized.\n",
    "  \n",
    "5. Given some distribution parameters, we know some data values are momre probable to occur than other data. For ex, for guassian, values around mean are more probable. In reality, we have observed the data, now in inverse problem, whats the likelihood function : L(parameters | x).\n",
    "\n",
    "\n",
    "6. . likelihood & Probability\n",
    "    Likelihood and Probability are two different things although they look and behaves same.    \n",
    "        a. L(parameters | x): likelihood of having these parameters, once the data are these. That is we are going to guess the model parameters from the data.          \n",
    "        b. probability P(x | parameters) : when we know the model parameters and when predicting a value from that model. So there we talk about how probable is the resultant value to be come out from that model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Bcos we are finding the given the data, what prob function would have most likely produced that data.\n",
    "$$ L(\\theta ; x) = \\prod f(x | \\theta)$$\n",
    "$$ L(\\theta ; x) = f(x_1 | \\theta). f(x_2 | \\theta)...f(x_n | \\theta)$$\n",
    "ie, we can check the likelihood of having mean = 2.5, std dev = 1 in above example by\n",
    "$$ L(\\mu = 2.5, \\sigma^2 = 1| x = 1,2,3,4) = pdf(x=1).pdf(x=2).pdf(x=3).pdf(x=4) $$\n",
    "$$ L(\\mu = 2.5, \\sigma^2 =1 | x = 1,2,3,4) = pdf(x=1).pdf(x=2).pdf(x=3).pdf(x=4) $$\n",
    "$$ pdf = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp{\\frac{-(x - \\mu)^2}{2\\sigma^2}}$$\n",
    "$$ L(\\mu = 2.5, \\sigma^2 =1 | x = 1,2,3,4) = some value $$\n",
    "This can be compared against other probable values for mean & std. High likelihood is better. But in math, this can be solved using derivations and precise values for parameters are obtained. The partial derivative is taken against the parameters and equated to zero to obtain the parameters.\n",
    "\n",
    "To make the L equation easily differentiable, we take log (natural log with base-e) on both sides. Adv it makes the product of pdfs (in RHS into sums). it makes exp(x) into x. Also log is monotonic(it increases along the value), so there is no harm choosing between gradient of L and log(L). \n",
    "\n",
    "$$ log (L(\\mu = 2.5, \\sigma^2 = 1| x = 1,2,3,4)) = \\log {(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}^4)} + \\log ({\\exp{\\frac{-(1 - \\mu)^2}{2\\sigma^2}}}) + \\log ({\\exp{\\frac{-(2 - \\mu)^2}{2\\sigma^2}}}) + \\log ({\\exp{\\frac{-(3 - \\mu)^2}{2\\sigma^2}}}) + \\log ({\\exp{\\frac{-(4 - \\mu)^2}{2\\sigma^2}}})$$\n",
    "\n",
    "The above eq shall be simplified and solved for mean and sigma. \n",
    "$$ RHS = -4\\log (\\sqrt{2\\pi\\sigma^2}) - \\frac{-(1 - \\mu)^2}{2\\sigma^2} -\\frac {-(2 - \\mu)^2}{2\\sigma^2} -  \\frac{-(3 - \\mu)^2}{2\\sigma^2} - \\frac{-(4 - \\mu)^2}{2\\sigma^2}  $$\n",
    "\n",
    "$$ \\frac {\\partial log(L)}{\\partial \\mu} = \\frac {\\partial RHS}{\\partial \\mu} $$\n",
    "\n",
    "$$ \\frac {\\partial log(L)}{\\partial \\sigma} = \\frac {\\partial RHS}{\\partial \\sigma} $$\n",
    "\n",
    "The both equations are solveable & we get precise unique solution.\n",
    "$$ Log likelihood = -\\frac{n}{2}\\log(2\\pi) - \\frac{n}{2}\\log(\\sigma^2) - \\frac {1}{2\\sigma^2}\\sum{(x_i - \\mu)^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLE in Linear Regression\n",
    "Things to keep in mind:    \n",
    "1. MLE can estimate the parameters given the data.\n",
    "2. But we need to know what kind of distributions to use?    \n",
    "Remember the target variable is assumed to follow normal distribution. \n",
    "$$ \\hat y = w_0 + w_1*x_1 + .. w_n*x_n $$\n",
    "Here the mean is not a single value but the prediction from model itself. So the mean varies as the input x varies. Basically along the regression line. So at each point on the line, we can have a prob curve which can itself have probable mean & std.\n",
    "$$ \\hat {Y}_{n*1} = {X}_{n*d} * {W}_{d*1} $$\n",
    "$$ L(XW, \\sigma^2|x) = \\prod f(y_i, x_iw, \\sigma^2)$$\n",
    "$$ L(XW, \\sigma^2|x) = \\prod \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp {\\frac{-(y_i - x_iw)^2}{2\\sigma^2}}$$\n",
    "When u solve this for mean and std dev we arrive at the linear reg solution\n",
    "$$ W = (X^TX)^{-1} X^TY $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Log Likelihood : -202.6380375411033\n"
    }
   ],
   "source": [
    "mu = x.mean()\n",
    "sigma = x.std()\n",
    "n = len(x)\n",
    "log_lhd = -n/2*np.log(2*np.pi) - n/2*np.sqrt(sigma**2)\n",
    "for i in x:\n",
    "    log_lhd += -(i - mu)**2/(2*sigma**2)\n",
    "print(f\"Log Likelihood : {log_lhd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "aic : 417.16, bic : 420.98404601085633\n"
    }
   ],
   "source": [
    "# Assuming Log-Likelihood = -206.58\n",
    "## AIC\n",
    "log_likelihood = -206.58\n",
    "k = 2\n",
    "aic = -2*log_likelihood + 2*k\n",
    "bic = -2*log_likelihood + 2*np.log(data.shape[0])\n",
    "print(f\" aic : {aic}, bic : {bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. F-statistic is more of hypothesis testing, where we test the significance of the predictor variables in the model. Are the predictor variables really useful in explaining the variances. The null hypothesis is all the predictor coefficients are zero & alternate hypothesis is atleast one of the predictor coefficients is non-zero. You build two models: one with all predictor variables and one without them(only intercept term). F-stat is basically the ratio of two variances thro these methods. Fstat is more at model level importance.\n",
    "2. Forumula fstat $$ \\frac {\\frac{SSE_{rr} - SSE_{ur}}{k}} {\\frac{SSE_{ur}}{n - k - 1}}$$\n",
    "3. SSE_ur is the sum of squared error with all predictor model. SSE_rr is sum of sqaured error with no predictor but only intercept.\n",
    "4. The numerator will always be positive as  the error will be lower when we include predictors. The denominator is mainly kept to normalize the f-stat as a constant and rather not to have any units associated.\n",
    "5. Once fstat is calculated, we need to look for critical Fvalue from fdistribution table. Lets say, we have 200 rows and 3 Xs. We have 2 Fs : F3, F196. There will be a fdist table with a value against F3, F196. If our calculated Fstat > Fcritical found from table. Then reject H0 hypothesis and conclude that predictor variables are significant.\n",
    "6. It also makes sense if the numerator is positive that the error is reduced with addition of Xs.\n",
    "7. In the exmaple : df1, df48 are the degrees of freedom of numerator and denominator respectivetly. numerator has one dof & denominator has 48 assuming k is equal to 1 (excluding intercept). In Ftable,\n",
    " the row values are for denominator and column values are for numerator. Get the value corresponding to pvalue(preferrably 0.05) & compare against calculated value of 89.56. Then accordingy reject/accept H0.     \n",
    "\n",
    "**Prob (F-Statistic)**   \n",
    "1. The value of Prob(F) is the probability that the null hypothesis for the full model is true (i.e., that all of the regression coefficients are zero).  For example, if Prob(F) has a value of 0.01000 then there is 1 chance in 100 that all of the regression parameters are zero.  This low a value would imply that at least some of the regression parameters are nonzero and that the regression equation does have some validity in fitting the data (i.e., the independent variables are not purely random with respect to the dependent variable). \n",
    "2. It is calculated using fvalue, df1, df48 and critical value of f.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "fstat : 89.56710653646776\n"
    }
   ],
   "source": [
    "#  fstat\n",
    "k = 1\n",
    "sse_rr = np.sum((y - np.mean(y))**2)\n",
    "sse_ur = np.sum((y - ypred)**2)\n",
    "fstat_numerator = (sse_rr - sse_ur)/(k)\n",
    "fstat_denominator = sse_ur/(n - k - 1)\n",
    "fstat = fstat_numerator/fstat_denominator\n",
    "print(f\"fstat : {fstat}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficient Standard Error & Tvalue & pvalue & Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run several runs with samples & estimate the coefficients m, c their average over all those runs might be very close the population m, c. To indicate how close, standard error can be looked at. The standard error of mean of Y is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Standard error tells how close the predicted coefficients are to the true coefficients. Smaller the SE, lower is the deviation. \n",
    "2. It decreases as N increases.\n",
    "$$ Standard  Error,  SE(m, c) = (X^T * X)^{-1} * \\frac{\\sum (y - \\hat y)^2}{(N - p)} $$\n",
    "3. SE can be used to perform hyp testing to know if there exists relationship btw X & Y.\n",
    "4. It is used to estimate the confidence intervals and pvalues (feature importance). Confidence interval in having the true unknown value of coefficients. Ex : 95% confidence interval range is the range of values such that 95% prob the range will contain the true unknown value of coefficients.\n",
    "$$ Confidence Interval = m +- 2* SE(m) $$\n",
    "$$ Confidence Interval = [m - 2* SE(m), m + 2* SE(m)] $$\n",
    "5. T statistics\n",
    "$$ tvalue = \\frac {coefficient}{SE_coefficient} $$\n",
    "\n",
    "6. tvalue says the number of std deviations the coefficients (m, c) are away from zero,indicating the coefficient importance and not being zero. So the tvalue can be higher than coefficient when the SE is lower.  If small pvalue is being observed from tstat, then u reject the null hyp that no relationship betw X & Y and conclude there exists a relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Standard Error 0 : 6.758\nStandard Error 1 : 0.416\nConfidence Interval c : [-31.0, -4.0]\nConfidence Interval m : [3.0, 5.0]\nt value c : -2.6\nt value m : 9.45\np value c : 0.012\np value m : 0.0\n"
    }
   ],
   "source": [
    "## Standard Error Calculation\n",
    "N = len(x)\n",
    "p = 1 + 1 # include the intercept as well\n",
    "X = np.empty(shape=(N, p))\n",
    "X[:, 0] = 1 # Intercept\n",
    "X[:,1:p] = data['speed'].values.reshape(-1,1) # Adding X values \n",
    "# coeff = np.linalg.inv(np.matmul(X.T, X))@X.T@y.values\n",
    "\n",
    "c, m  = ols_result.params.values\n",
    "ypred = m*data['speed'] + c\n",
    "residuals = y.values - ypred\n",
    "residuals_sum_of_squares = residuals.T @ residuals # @ is matrix multiplication\n",
    "sigma_sq = residuals_sum_of_squares/ (N - p)\n",
    "var_beta = np.linalg.inv(X.T @ X)*sigma_sq\n",
    "standard_error = []\n",
    "for i in range(p):\n",
    "    standard_error.append(round(var_beta[i,i]**0.5, 3))\n",
    "    print(f\"Standard Error {i} : {standard_error[i]}\")\n",
    "\n",
    "# Confidence Interval\n",
    "conf_interval_m = [m - 2*standard_error[1], m + 2*standard_error[1]]\n",
    "conf_interval_m = list(map(np.round, conf_interval_m))\n",
    "conf_interval_c = [c - 2*standard_error[0], c + 2*standard_error[0]]\n",
    "conf_interval_c = list(map(np.round, conf_interval_c))\n",
    "\n",
    "print(f\"Confidence Interval c : {conf_interval_c}\")\n",
    "print(f\"Confidence Interval m : {conf_interval_m}\")\n",
    "\n",
    "## Tvalue\n",
    "tvalue_m = round(m/standard_error[1], 2)\n",
    "tvalue_c = round(c/standard_error[0], 2)\n",
    "print(f\"t value c : {tvalue_c}\")\n",
    "print(f\"t value m : {tvalue_m}\")\n",
    "\n",
    "## pvalue\n",
    "from scipy import stats\n",
    "pvalue_m = 2 * (1 - stats.t.cdf(np.abs(tvalue_m), y.shape[0] - X.shape[1]))\n",
    "pvalue_c = 2 * (1 - stats.t.cdf(np.abs(tvalue_c), y.shape[0] - X.shape[1]))\n",
    "print(f\"p value c : {round(pvalue_c,3)}\")\n",
    "print(f\"p value m : {round(pvalue_m,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}