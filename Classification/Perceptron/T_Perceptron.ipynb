{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Take several binary inputs x1, x2,.. xn -> weighted sum  of inputs -> threshold the sum -> binary output\n",
    "\n",
    "* \\begin{equation}\n",
    "  output =\n",
    "    \\begin{cases}\n",
    "      0 \\ \\text{is $\\sum$ wx < threshold}\\\\\n",
    "      1 \\ \\text{is $\\sum$ wx >= threshold} \\\\\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "\n",
    "* You need:\n",
    "  * Binary Features (x)\n",
    "  * Weights (w)\n",
    "  * threshold values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition of perceptron\n",
    "\n",
    "* You want to go festival based on features like:\n",
    "    * x1 - Weather being good \n",
    "    * x2 - friend accompanying\n",
    "    * x3 - Car available\n",
    "    * All are binary 0 (no) and 1 (yes)\n",
    "\n",
    "* Weights - having preference on these features.\n",
    "    * You want to attend irrepective of x2 and x3. \n",
    "    * But x1 is more important as bad weather can hinder attending festival\n",
    "    * w1 - 6\n",
    "    * w2, w3 - 2\n",
    "\n",
    "* Threshold\n",
    "    * if 5 -> it will always output 1 regardless of x2, x3.\n",
    "    * Lower Threshold -> more willing to attend festival\n",
    "\n",
    "* Points to note:\n",
    "    * Diff values of w, Threshold yields diff decision making or diff models\n",
    "    * Multi Layer Perceptrons\n",
    "        * The above ex depends on simple decisions, but in practice the decision making is complex and depends on interactive factors\n",
    "        * Perceptrons in second Layer can make complex decision and more abstract level than at 1st layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying the output equation\n",
    "\n",
    "* \\begin{equation}\n",
    "  output =\n",
    "    \\begin{cases}\n",
    "      0 \\ \\text{is wx + b < 0}\\\\\n",
    "      1 \\ \\text{is wx + b >= 0} \\\\\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "* where wx is the dot product and b is the -threshold\n",
    "\n",
    "* Big bias -> more probable to output 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Neurons Motivation : Why learning is difficult in perceptrons \n",
    "\n",
    "* To move away from classic perceprtons -> make learning possible\n",
    "\n",
    "* Learning : Suppose a small change in weight or bias to cause corresponding small change in output\n",
    "\n",
    "* In perceptrons:\n",
    "    * small change in w or b can completely flip the output from like -> 1 to 0\n",
    "    * This flip can alter the rest of the network too ie. classifying 9 as 9 would work but others might get affected \n",
    "    * Making difficult to how gradually changing w, b so it predicts outputs well\n",
    "\n",
    "* Sigmoid neurons -> small changes in w, b can cause only small changes in output -> allows network learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Neurons\n",
    "\n",
    "* Instead of binary inputs, sigmoid can any value btw 0-1\n",
    "\n",
    "* Output -> sigmoid of (wx +b) -> output is not betw 0-1\n",
    "\n",
    "* for inputs (x), weights (w), bias (b):\n",
    "    $$ \\sigma(z) = \\frac{1}{1 + exp[-(\\sum {wx + b})]} $$\n",
    "\n",
    "* Sigmoid Vs Step Function:\n",
    "    * For extreme + and - values of (wx + b) the output of both sigmoid and perceptron is same\n",
    "    * In modest range of values, the output differs. Sigmoid gives continous values btw 0-1\n",
    "    \n",
    "    * perceptron checks only if + or - for predicting 1 or 0 -> small change in w, b need not imply small change in output\n",
    "    * Whereas, sigmoid function is relatively smoother -> you can expect small change in output for corresponding change in w, b\n",
    "\n",
    "    * $$ \\Delta output = \\sum \\frac{\\partial output}{\\partial w} \\Delta w + \\frac{\\partial output}{\\partial b} \\Delta b $$\n",
    "    \n",
    "    * The output del is linear function of its w, b -> learning easier -> we know how changing weights changes outputs"
   ]
  }
 ]
}