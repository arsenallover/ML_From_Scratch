{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595260335868",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.read_csv(r\"Data\\lending-club-data.csv\", index_col = 0)\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home_ownership status: own, mortgage or rent\n",
    "            'emp_length']         # number of years of employment\n",
    "target = 'safe_loans'\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Percentage of safe loans                 : 0.5\nPercentage of risky loans                : 0.5\nTotal number of loans in our new dataset : 46300\n"
    }
   ],
   "source": [
    "# Balancing the data\n",
    "safe_loans_raw = loans[loans[target] == 1]\n",
    "risky_loans_raw = loans[loans[target] == -1]\n",
    "\n",
    "# Since there are less risky loans than safe loans, find the ratio of the sizes\n",
    "# and use that percentage to undersample the safe loans.\n",
    "percentage = len(risky_loans_raw)/float(len(safe_loans_raw))\n",
    "safe_loans = safe_loans_raw.sample(n = len(risky_loans_raw), random_state = 1)\n",
    "risky_loans = risky_loans_raw\n",
    "loans_data = risky_loans.append(safe_loans)\n",
    "\n",
    "print(\"Percentage of safe loans                 :\", len(safe_loans) / float(len(loans_data)))\n",
    "print(\"Percentage of risky loans                :\", len(risky_loans) / float(len(loans_data)))\n",
    "print(\"Total number of loans in our new dataset :\", len(loans_data))\n",
    "del safe_loans_raw, risky_loans_raw, risky_loans, safe_loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   safe_loans  grade_A  grade_B  grade_C  grade_D  grade_E  grade_F  grade_G  term_ 36 months  term_ 60 months  home_ownership_MORTGAGE  home_ownership_OTHER  home_ownership_OWN  home_ownership_RENT  emp_length_1 year  emp_length_10+ years  emp_length_2 years  emp_length_3 years  emp_length_4 years  emp_length_5 years  emp_length_6 years  emp_length_7 years  emp_length_8 years  emp_length_9 years  emp_length_< 1 year\n0          -1        0        0        1        0        0        0        0                0                1                        0                     0                   0                    1                  0                     0                   0                   0                   0                   0                   0                   0                   0                   0                    1\n1          -1        0        0        0        0        0        1        0                0                1                        0                     0                   1                    0                  0                     0                   0                   0                   1                   0                   0                   0                   0                   0                    0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>safe_loans</th>\n      <th>grade_A</th>\n      <th>grade_B</th>\n      <th>grade_C</th>\n      <th>grade_D</th>\n      <th>grade_E</th>\n      <th>grade_F</th>\n      <th>grade_G</th>\n      <th>term_ 36 months</th>\n      <th>term_ 60 months</th>\n      <th>home_ownership_MORTGAGE</th>\n      <th>home_ownership_OTHER</th>\n      <th>home_ownership_OWN</th>\n      <th>home_ownership_RENT</th>\n      <th>emp_length_1 year</th>\n      <th>emp_length_10+ years</th>\n      <th>emp_length_2 years</th>\n      <th>emp_length_3 years</th>\n      <th>emp_length_4 years</th>\n      <th>emp_length_5 years</th>\n      <th>emp_length_6 years</th>\n      <th>emp_length_7 years</th>\n      <th>emp_length_8 years</th>\n      <th>emp_length_9 years</th>\n      <th>emp_length_&lt; 1 year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "loans_data = pd.get_dummies(loans_data).reset_index(drop = True)\n",
    "loans_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = loans_data.columns.to_list()\n",
    "features.remove('safe_loans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def intermediate_node_mistakes(df):\n",
    "    ''' Return Number of Mistakes at node '''\n",
    "    if len(df) == 0:\n",
    "        return 0\n",
    "\n",
    "    safe_loans_num = (df == +1).sum()\n",
    "    risky_loans_num = (df == -1).sum()\n",
    "    # print(safe_loans_num)\n",
    "    if safe_loans_num > risky_loans_num:\n",
    "        return risky_loans_num\n",
    "    else:\n",
    "        return safe_loans_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_feature_split(data, features):\n",
    "    ''' Return best feature at a decision stump '''\n",
    "    best_error = 10\n",
    "    best_feature = []\n",
    "    for feature in features:\n",
    "        left_split = data[data[feature] == 0]\n",
    "        right_split = data[data[feature] == 1]\n",
    "\n",
    "        left_mistakes = intermediate_node_mistakes(left_split['safe_loans'])\n",
    "        right_mistakes = intermediate_node_mistakes(right_split['safe_loans'])\n",
    "\n",
    "        error = (left_mistakes + right_mistakes)/len(data)\n",
    "\n",
    "        if error < best_error:\n",
    "            best_error, best_feature = error, feature\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tree(data, features, target, current_depth = 0, max_depth = 4, min_node_size = 10, min_error_reduction=0.0):\n",
    "\n",
    "    \n",
    "    remaining_features = features[:]\n",
    "    target_values = data[target]\n",
    "\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    print(\"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values)))\n",
    "    \n",
    "    \n",
    "    # Stopping condition 1: All nodes are of the same type.\n",
    "    if intermediate_node_mistakes(target_values) == 0:\n",
    "        print(\"Stopping condition 1 reached. All data points have the same target value.\")                \n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # Stopping condition 2: No more features to split on.\n",
    "    if remaining_features == []:\n",
    "        print(\"Stopping condition 2 reached. No remaining features.\")                \n",
    "        return create_leaf(target_values)    \n",
    "    \n",
    "    # Early stopping condition 1: Reached max depth limit.\n",
    "    if current_depth >= max_depth:\n",
    "        print(\"Early stopping condition 1 reached. Reached maximum depth.\")\n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # Early stopping condition 2: Reached the minimum node size.\n",
    "    # If the number of data points is less than or equal to the minimum size, return a leaf.\n",
    "    if  len(data) < min_node_size:       ## YOUR CODE HERE \n",
    "        print(\"Early stopping condition 2 reached. Reached minimum node size.\")\n",
    "        return create_leaf(target_values)## YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "    splitting_feature = best_feature_split(data, features)\n",
    "    \n",
    "    left_tree_data = data[data[splitting_feature] == 0]\n",
    "    right_tree_data = data[data[splitting_feature] == 1]\n",
    "\n",
    "    error_before_split = intermediate_node_mistakes(target_values)/len(data)\n",
    "\n",
    "    left_miskates = intermediate_node_mistakes(left_tree_data[target])\n",
    "    right_miskates = intermediate_node_mistakes(right_tree_data[target])\n",
    "    error_after_split = (left_miskates + right_miskates)/len(data)\n",
    "\n",
    "    error_change = error_after_split - error_before_split\n",
    "    if error_change < min_error_reduction:\n",
    "        create_leaf(target_values)\n",
    "    print(splitting_feature)\n",
    "    remaining_features.remove(splitting_feature)\n",
    "    left_tree = generate_tree(left_tree_data, remaining_features, target,  current_depth = current_depth+1, max_depth = 4, min_node_size = 10, min_error_reduction=0.0)\n",
    "    right_tree = generate_tree(right_tree_data, remaining_features, target, current_depth = current_depth+1, max_depth = 4, min_node_size = 10, min_error_reduction=0.0)\n",
    "\n",
    "    return {'is_leaf'          : False, \n",
    "        'prediction'       : None,\n",
    "        'splitting_feature': splitting_feature,\n",
    "        'left'             : left_tree, \n",
    "        'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(target_values):\n",
    "    leaf = {'is_leaf'          : True, \n",
    "        'prediction'       : None,\n",
    "        'splitting_feature': None,\n",
    "        'left'             : None, \n",
    "        'right'            : None}\n",
    "\n",
    "    safe_loan = (target_values == +1).sum()\n",
    "    risky_loan = (target_values == -1).sum()\n",
    "    if safe_loan > risky_loan:\n",
    "        leaf['prediction'] = +1\n",
    "    else:\n",
    "        leaf['prediction'] = -1\n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--------------------------------------------------------------------\nSubtree, depth = 0 (46300 data points).\nterm_ 36 months\n--------------------------------------------------------------------\nSubtree, depth = 1 (11671 data points).\ngrade_A\n--------------------------------------------------------------------\nSubtree, depth = 2 (11515 data points).\ngrade_B\n--------------------------------------------------------------------\nSubtree, depth = 3 (10167 data points).\ngrade_C\n--------------------------------------------------------------------\nSubtree, depth = 4 (7369 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 4 (2798 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 3 (1348 data points).\nemp_length_3 years\n--------------------------------------------------------------------\nSubtree, depth = 4 (1244 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 4 (104 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 2 (156 data points).\ngrade_B\n--------------------------------------------------------------------\nSubtree, depth = 3 (156 data points).\ngrade_C\n--------------------------------------------------------------------\nSubtree, depth = 4 (156 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 4 (0 data points).\nStopping condition 1 reached. All data points have the same target value.\n--------------------------------------------------------------------\nSubtree, depth = 3 (0 data points).\nStopping condition 1 reached. All data points have the same target value.\n--------------------------------------------------------------------\nSubtree, depth = 1 (34629 data points).\ngrade_D\n--------------------------------------------------------------------\nSubtree, depth = 2 (28778 data points).\ngrade_E\n--------------------------------------------------------------------\nSubtree, depth = 3 (27187 data points).\ngrade_C\n--------------------------------------------------------------------\nSubtree, depth = 4 (18252 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 4 (8935 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 3 (1591 data points).\ngrade_A\n--------------------------------------------------------------------\nSubtree, depth = 4 (1591 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 4 (0 data points).\nStopping condition 1 reached. All data points have the same target value.\n--------------------------------------------------------------------\nSubtree, depth = 2 (5851 data points).\ngrade_A\n--------------------------------------------------------------------\nSubtree, depth = 3 (5851 data points).\ngrade_B\n--------------------------------------------------------------------\nSubtree, depth = 4 (5851 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 4 (0 data points).\nStopping condition 1 reached. All data points have the same target value.\n--------------------------------------------------------------------\nSubtree, depth = 3 (0 data points).\nStopping condition 1 reached. All data points have the same target value.\n"
    }
   ],
   "source": [
    "small_decision_tree = generate_tree(loans_data, features, 'safe_loans', max_depth = 4, \n",
    "                                        min_node_size = 10, min_error_reduction=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, x):\n",
    "    if tree['is_leaf']:\n",
    "        return tree['prediction']\n",
    "    else:\n",
    "        # print(tree['splitting_feature'])\n",
    "        splitting_feature_value = x[tree['splitting_feature']]\n",
    "        if splitting_feature_value == 0:\n",
    "            # print(0)\n",
    "            return classify(tree['left'], x)\n",
    "        else:\n",
    "            # print(1)\n",
    "            return classify(tree['right'], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_data['prediction'] = 99\n",
    "for i in np.arange(len(loans_data)):\n",
    "    loans_data['prediction'][i] = classify(small_decision_tree, loans_data.iloc[i,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-1    27788\n 1    18512\nName: prediction, dtype: int64"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "loans_data['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.609805615550756"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "(loans_data['prediction'] == loans_data['safe_loans']).sum()/len(loans_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "1. The recursion aspect of building tree is critical.   \n",
    "2. The above example examines only categorical features for simplicity. \n",
    "3. Remember the three stopping criteria. Always have code for edge cases (like when all target values at start belong to same class)\n",
    "4. The early stopping can affect the overfitting scenarios. That can be checked with low, medium and high values for each criteria. The model complexity can be checked at number of leave nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}