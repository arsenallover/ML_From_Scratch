{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "\n",
    "class LDA():\n",
    "    def __init__(self, data, num_dims = 1, convert_data = 0, \n",
    "                 percentile = 50, threshold = 0, labelcol = -1, split_ratio = 0.9):\n",
    "        '''\n",
    "        Class constructor.\n",
    "        --------------------------------\n",
    "        data : the entire dataset\n",
    "        num_dims : number of dimensions to project data into\n",
    "        convert_data : flag to specify whether the data is to be converted to categorical\n",
    "        percentile : if convert_data is True, then specify the percentile for conversion\n",
    "        threshold : flag to indicate whether to do thresholding or gaussian modeling for classification\n",
    "        labelcol : which column in the csv data contains the label\n",
    "        split_ratio : split ratio for train-test split\n",
    "        '''\n",
    "        self.data = data\n",
    "        self.num_dims = num_dims\n",
    "        self.convert_data = convert_data\n",
    "        self.percentile = percentile\n",
    "        self.threshold = threshold\n",
    "        self.labelcol = labelcol\n",
    "        self.split_ratio = split_ratio\n",
    "        if (self.convert_data):\n",
    "            self.data = self.to_categorical(self.data, self.percentile)\n",
    "\n",
    "    '''\n",
    "    Function to convert data to categorical.\n",
    "    To be used only for the boston dataset.\n",
    "    '''\n",
    "    def to_categorical(self, data, percentile):\n",
    "        fraction = percentile / 100.0\n",
    "\n",
    "        # partition data based on percentile of label column\n",
    "        med = data.loc[:, self.labelcol].quantile(fraction)\n",
    "        for i in range(data.shape[0]):\n",
    "            if (data.loc[i, self.labelcol] >= med):\n",
    "                data.loc[i, self.labelcol] = 1 \n",
    "            else:\n",
    "                data.loc[i, self.labelcol] = 0 \n",
    "\n",
    "        return data\n",
    "\n",
    "    '''\n",
    "    Utility function to drop some column from the given pandas dataframe.\n",
    "    '''\n",
    "    def drop_col(self, data, col):\n",
    "        return data.drop(col, axis = 1)\n",
    "\n",
    "    '''\n",
    "    Main function to apply LDA\n",
    "    '''\n",
    "    def fit(self):\n",
    "        # Function estimates the LDA parameters\n",
    "        def estimate_params(data):\n",
    "            # group data by label column\n",
    "            grouped = data.groupby(self.data.loc[:,self.labelcol])\n",
    "\n",
    "            # calculate means for each class\n",
    "            means = {}\n",
    "            for c in self.classes:\n",
    "                means[c] = np.array(self.drop_col(self.classwise[c], self.labelcol).mean(axis = 0))\n",
    "\n",
    "            # calculate the overall mean of all the data\n",
    "            overall_mean = np.array(self.drop_col(data, self.labelcol).mean(axis = 0))\n",
    "\n",
    "            # calculate between class covariance matrix\n",
    "            # S_B = \\sigma{N_i (m_i - m) (m_i - m).T}\n",
    "            S_B = np.zeros((data.shape[1] - 1, data.shape[1] - 1))\n",
    "            for c in means.keys():\n",
    "                S_B += np.multiply(len(self.classwise[c]),\n",
    "                                   np.outer((means[c] - overall_mean), \n",
    "                                            (means[c] - overall_mean)))\n",
    "\n",
    "            # calculate within class covariance matrix\n",
    "            # S_W = \\sigma{S_i}\n",
    "            # S_i = \\sigma{(x - m_i) (x - m_i).T}\n",
    "            S_W = np.zeros(S_B.shape) \n",
    "            for c in self.classes: \n",
    "                tmp = np.subtract(self.drop_col(self.classwise[c], self.labelcol).T, np.expand_dims(means[c], axis=1))\n",
    "                S_W = np.add(np.dot(tmp, tmp.T), S_W)\n",
    "\n",
    "            # objective : find eigenvalue, eigenvector pairs for inv(S_W).S_B\n",
    "            mat = np.dot(np.linalg.pinv(S_W), S_B)\n",
    "            eigvals, eigvecs = np.linalg.eig(mat)\n",
    "            eiglist = [(eigvals[i], eigvecs[:, i]) for i in range(len(eigvals))]\n",
    "\n",
    "            # sort the eigvals in decreasing order\n",
    "            eiglist = sorted(eiglist, key = lambda x : x[0], reverse = True)\n",
    "\n",
    "            # take the first num_dims eigvectors\n",
    "            w = np.array([eiglist[i][1] for i in range(self.num_dims)])\n",
    "\n",
    "            self.w = w\n",
    "            self.means = means\n",
    "            return\n",
    "\n",
    "\n",
    "        # perform train-test split\n",
    "        traindata = []\n",
    "        testdata = []\n",
    "        # group data by label column\n",
    "        grouped = data.groupby(self.data.loc[:,self.labelcol])\n",
    "        self.classes = [c for c in grouped.groups.keys()]\n",
    "        self.classwise = {} \n",
    "        for c in self.classes:\n",
    "            self.classwise[c] = grouped.get_group(c)\n",
    "            rows = random.sample(list(self.classwise[c].index), \n",
    "                                     int(self.classwise[c].shape[0] * \n",
    "                                     self.split_ratio))\n",
    "            traindata.append(self.classwise[c].loc[rows])\n",
    "            testdata.append(self.classwise[c].drop(rows))\n",
    "\n",
    "        traindata = pd.concat(traindata)\n",
    "        testdata = pd.concat(testdata)\n",
    "\n",
    "        # estimate the LDA parameters\n",
    "        estimate_params(traindata)\n",
    "        # perform classification on test set\n",
    "        # if the method is threshold\n",
    "        if (self.threshold):\n",
    "            self.calculate_threshold()\n",
    "            # append the training and test error rates for this iteration\n",
    "            trainerror = self.calculate_score(traindata) / float(traindata.shape[0])\n",
    "                                                                \n",
    "            testerror = self.calculate_score(testdata) / float(testdata.shape[0])\n",
    "\n",
    "        # if the method is gaussian modeling\n",
    "        else:\n",
    "            self.gaussian_modeling()\n",
    "            # append the training and test error rates for this iteration\n",
    "            trainerror = self.calculate_score_gaussian(traindata) / float(traindata.shape[0])\n",
    "            testerror = self.calculate_score_gaussian(testdata) / float(testdata.shape[0])\n",
    "\n",
    "        return trainerror, testerror\n",
    "\n",
    "    '''\n",
    "    Function to calculate the classification threshold.\n",
    "    Projects the means of the classes and takes their mean as the threshold.\n",
    "    Also specifies whether values greater than the threshold fall into class 1 \n",
    "    or class 2.\n",
    "    '''\n",
    "    def calculate_threshold(self):\n",
    "        # project the means and take their mean\n",
    "        tot = 0\n",
    "        for c in self.means.keys():\n",
    "            tot += np.dot(self.w, self.means[c])\n",
    "        self.w0 = 0.5 * tot\n",
    "\n",
    "        # for 2 classes case; mark if class 1 is >= w0 or < w0\n",
    "        c1 = self.means.keys()[0]\n",
    "        c2 = self.means.keys()[1]\n",
    "        mu1 = np.dot(self.w, self.means[c1])\n",
    "        if (mu1 >= self.w0):\n",
    "            self.c1 = 'ge'\n",
    "        else:\n",
    "            self.c1 = 'l'\n",
    "\n",
    "    '''\n",
    "    Function to calculate the scores in thresholding method.\n",
    "    Assigns predictions based on the calculated threshold.\n",
    "    '''\n",
    "    def calculate_score(self, data):\n",
    "        inputs = self.drop_col(data, self.labelcol)\n",
    "        # project the inputs\n",
    "        proj = np.dot(self.w, inputs.T).T\n",
    "        # assign the predicted class\n",
    "        c1 = self.means.keys()[0]\n",
    "        c2 = self.means.keys()[1]\n",
    "        if (self.c1 == 'ge'):\n",
    "            proj = [c1 if proj[i] >= self.w0 else c2 for i in range(len(proj))]\n",
    "        else:\n",
    "            proj = [c1 if proj[i] < self.w0 else c2 for i in range(len(proj))]\n",
    "        # calculate the number of errors made\n",
    "        errors = (proj != data.loc[:, self.labelcol])\n",
    "        return sum(errors)\n",
    "\n",
    "    '''\n",
    "    Function to estimate gaussian models for each class.\n",
    "    Estimates priors, means and covariances for each class.\n",
    "    '''\n",
    "    def gaussian_modeling(self):\n",
    "        self.priors = {}\n",
    "        self.gaussian_means = {}\n",
    "        self.gaussian_cov = {}\n",
    "\n",
    "        for c in self.means.keys():\n",
    "            inputs = self.drop_col(self.classwise[c], self.labelcol)\n",
    "            proj = np.dot(self.w, inputs.T).T\n",
    "            self.priors[c] = inputs.shape[0] / float(self.data.shape[0])\n",
    "            self.gaussian_means[c] = np.mean(proj, axis = 0)\n",
    "            self.gaussian_cov[c] = np.cov(proj, rowvar=False)\n",
    "\n",
    "    '''\n",
    "    Utility function to return the probability density for a gaussian, given an \n",
    "    input point, gaussian mean and covariance.\n",
    "    '''\n",
    "    def pdf(self, point, mean, cov):\n",
    "        cons = 1./((2*np.pi)**(len(point)/2.)*np.linalg.det(cov)**(-0.5))\n",
    "        return cons*np.exp(-np.dot(np.dot((point-mean),np.linalg.inv(cov)),(point-mean).T)/2.)\n",
    "\n",
    "    '''\n",
    "    Function to calculate error rates based on gaussian modeling.\n",
    "    '''\n",
    "    def calculate_score_gaussian(self, data):\n",
    "        classes = sorted(list(self.means.keys()))\n",
    "        inputs = self.drop_col(data, self.labelcol)\n",
    "        # project the inputs\n",
    "        proj = np.dot(self.w, inputs.T).T\n",
    "        # calculate the likelihoods for each class based on the gaussian models\n",
    "        likelihoods = np.array([[self.priors[c] * self.pdf([x[ind] for ind in \n",
    "                                                            range(len(x))], self.gaussian_means[c], \n",
    "                               self.gaussian_cov[c]) for c in \n",
    "                        classes] for x in proj])\n",
    "        # assign prediction labels based on the highest probability\n",
    "        labels = np.argmax(likelihoods, axis = 1)\n",
    "        errors = np.sum(labels != data.loc[:, self.labelcol])\n",
    "        return errors\n",
    "\n",
    "    def plot_bivariate_gaussians(self):\n",
    "        classes = list(self.means.keys())\n",
    "        colors = cm.rainbow(np.linspace(0, 1, len(classes)))\n",
    "        plotlabels = {classes[c] : colors[c] for c in range(len(classes))}\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax3D = fig.add_subplot(111, projection='3d')\n",
    "        for c in self.means.keys():\n",
    "            data = np.random.multivariate_normal(self.gaussian_means[c], \n",
    "                                                 self.gaussian_cov[c], size=100)\n",
    "            pdf = np.zeros(data.shape[0])\n",
    "            cons = 1./((2*np.pi)**(data.shape[1]/2.)*np.linalg.det(self.gaussian_cov[c])**(-0.5))\n",
    "            X, Y = np.meshgrid(data.T[0], data.T[1])\n",
    "            def pdf(point):\n",
    "                return cons*np.exp(-np.dot(np.dot((point-self.gaussian_means[c]),np.linalg.inv(self.gaussian_cov[c])),(point-self.gaussian_means[c]).T)/2.)\n",
    "\n",
    "            zs = np.array([pdf(np.array(ponit)) for ponit in zip(np.ravel(X), \n",
    "                                                                   np.ravel(Y))])\n",
    "            Z = zs.reshape(X.shape)\n",
    "            surf = ax3D.plot_surface(X, Y, Z, rstride=1, cstride=1, \n",
    "                                       color=plotlabels[c], linewidth=0, \n",
    "                                       antialiased=False)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_proj_1D(self, data):\n",
    "        classes = list(self.means.keys())\n",
    "        colors = cm.rainbow(np.linspace(0, 1, len(classes)))\n",
    "        plotlabels = {classes[c] : colors[c] for c in range(len(classes))}\n",
    "\n",
    "        fig = plt.figure()\n",
    "        for i, row in data.iterrows():\n",
    "            proj = np.dot(self.w, row[:-1])\n",
    "            plt.scatter(proj, np.random.normal(0,1,1)+0, color = \n",
    "                        plotlabels[row[self.labelcol]])\n",
    "        plt.show()\n",
    "\n",
    "    def plot_proj_2D(self, data):\n",
    "        classes = list(self.means.keys())\n",
    "        colors = cm.rainbow(np.linspace(0, 1, len(classes)))\n",
    "        plotlabels = {classes[c] : colors[c] for c in range(len(classes))}\n",
    "\n",
    "        fig = plt.figure()\n",
    "        for i, row in data.iterrows():\n",
    "            proj = np.dot(self.w, row[:-1])\n",
    "            plt.scatter(proj[0], proj[1], color = \n",
    "                        plotlabels[row[self.labelcol]])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "from lda import LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Data/Iris.csv\", index_col = 0)\n",
    "data = data[data['class label'] == 'Iris-setosa'].reset_index(drop=True)\n",
    "labelcol = 'class label'\n",
    "lda = LDA(data, num_dims=2, convert_data=0, threshold=0, labelcol=labelcol)\n",
    "trainerror, testerror = lda.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(\"Data/Iris.csv\", index_col = 0)\n",
    "data = data[data['class label'] == 'Iris-setosa'].reset_index(drop=True)\n",
    "labelcol = 'class label'\n",
    "lda = LDA(data, num_dims=2, convert_data=0, threshold=0, labelcol=labelcol)\n",
    "trainerror, testerror = lda.fit()\n",
    "print(trainerror)\n",
    "print(testerror)\n",
    "#print(verifyLDA(data, data, labelcol))\n",
    "lda.plot_proj_2D(data)\n",
    "lda.plot_bivariate_gaussians()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}