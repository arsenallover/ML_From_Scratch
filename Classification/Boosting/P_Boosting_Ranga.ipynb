{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595345511227",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.read_csv(r\"Data\\lending-club-data.csv\", index_col = 0)\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home_ownership status: own, mortgage or rent\n",
    "            'emp_length']         # number of years of employment\n",
    "target = 'safe_loans'\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Percentage of safe loans                 : 0.5\nPercentage of risky loans                : 0.5\nTotal number of loans in our new dataset : 46300\n"
    }
   ],
   "source": [
    "# Balancing the data\n",
    "safe_loans_raw = loans[loans[target] == 1]\n",
    "risky_loans_raw = loans[loans[target] == -1]\n",
    "\n",
    "# Since there are less risky loans than safe loans, find the ratio of the sizes\n",
    "# and use that percentage to undersample the safe loans.\n",
    "percentage = len(risky_loans_raw)/float(len(safe_loans_raw))\n",
    "safe_loans = safe_loans_raw.sample(n = len(risky_loans_raw), random_state = 1)\n",
    "risky_loans = risky_loans_raw\n",
    "loans_data = risky_loans.append(safe_loans)\n",
    "\n",
    "print(\"Percentage of safe loans                 :\", len(safe_loans) / float(len(loans_data)))\n",
    "print(\"Percentage of risky loans                :\", len(risky_loans) / float(len(loans_data)))\n",
    "print(\"Total number of loans in our new dataset :\", len(loans_data))\n",
    "del safe_loans_raw, risky_loans_raw, risky_loans, safe_loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   safe_loans  grade_A  grade_B  grade_C  grade_D  grade_E  grade_F  grade_G  term_ 36 months  term_ 60 months  home_ownership_MORTGAGE  home_ownership_OTHER  home_ownership_OWN  home_ownership_RENT  emp_length_1 year  emp_length_10+ years  emp_length_2 years  emp_length_3 years  emp_length_4 years  emp_length_5 years  emp_length_6 years  emp_length_7 years  emp_length_8 years  emp_length_9 years  emp_length_< 1 year\n0          -1        0        0        1        0        0        0        0                0                1                        0                     0                   0                    1                  0                     0                   0                   0                   0                   0                   0                   0                   0                   0                    1\n1          -1        0        0        0        0        0        1        0                0                1                        0                     0                   1                    0                  0                     0                   0                   0                   1                   0                   0                   0                   0                   0                    0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>safe_loans</th>\n      <th>grade_A</th>\n      <th>grade_B</th>\n      <th>grade_C</th>\n      <th>grade_D</th>\n      <th>grade_E</th>\n      <th>grade_F</th>\n      <th>grade_G</th>\n      <th>term_ 36 months</th>\n      <th>term_ 60 months</th>\n      <th>home_ownership_MORTGAGE</th>\n      <th>home_ownership_OTHER</th>\n      <th>home_ownership_OWN</th>\n      <th>home_ownership_RENT</th>\n      <th>emp_length_1 year</th>\n      <th>emp_length_10+ years</th>\n      <th>emp_length_2 years</th>\n      <th>emp_length_3 years</th>\n      <th>emp_length_4 years</th>\n      <th>emp_length_5 years</th>\n      <th>emp_length_6 years</th>\n      <th>emp_length_7 years</th>\n      <th>emp_length_8 years</th>\n      <th>emp_length_9 years</th>\n      <th>emp_length_&lt; 1 year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "loans_data = pd.get_dummies(loans_data).reset_index(drop = True)\n",
    "loans_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = loans_data.columns.to_list()\n",
    "features.remove('safe_loans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree_weight(df):\n",
    "    ''' Return individual tree weight '''\n",
    "    error_rate = (df['safe_loans'] == df['predictions']).sum()/len(output)\n",
    "    weight = -1/2*np.log((1 - error_rate)/error_rate)\n",
    "    return weight\n",
    "\n",
    "def get_data_weight(df):\n",
    "    ''' Return updated weights to data based on misclassification '''\n",
    "    if df['safe_loans'] == df['predictions']:\n",
    "        return df['weights']*np.exp(-df['weights'])\n",
    "    else:\n",
    "        return df['weights']*np.exp(df['weights'])\n",
    "\n",
    "junk['new_weight'] = junk.apply(get_data_weight, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def intermediate_node_mistakes(df):\n",
    "    ''' Return Number of Mistakes at node '''\n",
    "    if len(df) == 0:\n",
    "        return 0\n",
    "\n",
    "    safe_loans_num = (df == +1).sum()\n",
    "    risky_loans_num = (df == -1).sum()\n",
    "    # print(safe_loans_num)\n",
    "    if safe_loans_num > risky_loans_num:\n",
    "        return risky_loans_num\n",
    "    else:\n",
    "        return safe_loans_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_feature_split(data, features):\n",
    "    ''' Return best feature at a decision stump '''\n",
    "    best_error = 10\n",
    "    best_feature = []\n",
    "    for feature in features:\n",
    "        left_split = data[data[feature] == 0]\n",
    "        right_split = data[data[feature] == 1]\n",
    "\n",
    "        left_mistakes = intermediate_node_mistakes(left_split['safe_loans'])\n",
    "        right_mistakes = intermediate_node_mistakes(right_split['safe_loans'])\n",
    "\n",
    "        error = (left_mistakes + right_mistakes)/len(data)\n",
    "\n",
    "        if error < best_error:\n",
    "            best_error, best_feature = error, feature\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_predictions(weigths_all, predictions_all):\n",
    "    return np.dot(weight_all, prediction_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_boosted_tree(data, features, target, num_trees = 2, max_depth = 1):\n",
    "\n",
    "    weights_all = []\n",
    "    prediction_all = np.array(shape = (len(data), num_trees))\n",
    "\n",
    "    for tree in np.arange(num_trees):    \n",
    "        remaining_features = features[:]\n",
    "        target_values = data[target]\n",
    "        \n",
    "        splitting_feature = best_feature_split(data, features)\n",
    "        prediction = \n",
    "        left_tree_data = data[data[splitting_feature] == 0]\n",
    "        right_tree_data = data[data[splitting_feature] == 1]\n",
    "\n",
    "    return {'is_leaf'          : False, \n",
    "        'prediction'       : None,\n",
    "        'splitting_feature': splitting_feature,\n",
    "        'left'             : left_tree, \n",
    "        'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(target_values):\n",
    "    leaf = {'is_leaf'          : True, \n",
    "        'prediction'       : None,\n",
    "        'splitting_feature': None,\n",
    "        'left'             : None, \n",
    "        'right'            : None}\n",
    "\n",
    "    safe_loan = (target_values == +1).sum()\n",
    "    risky_loan = (target_values == -1).sum()\n",
    "    if safe_loan > risky_loan:\n",
    "        leaf['prediction'] = +1\n",
    "    else:\n",
    "        leaf['prediction'] = -1\n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--------------------------------------------------------------------\nSubtree, depth = 0 (46300 data points).\nterm_ 36 months\n--------------------------------------------------------------------\nSubtree, depth = 1 (11671 data points).\ngrade_A\n--------------------------------------------------------------------\nSubtree, depth = 2 (11515 data points).\ngrade_B\n--------------------------------------------------------------------\nSubtree, depth = 3 (10167 data points).\ngrade_C\n--------------------------------------------------------------------\nSubtree, depth = 4 (7369 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 4 (2798 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 3 (1348 data points).\nemp_length_3 years\n--------------------------------------------------------------------\nSubtree, depth = 4 (1244 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 4 (104 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 2 (156 data points).\ngrade_B\n--------------------------------------------------------------------\nSubtree, depth = 3 (156 data points).\ngrade_C\n--------------------------------------------------------------------\nSubtree, depth = 4 (156 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 4 (0 data points).\nStopping condition 1 reached. All data points have the same target value.\n--------------------------------------------------------------------\nSubtree, depth = 3 (0 data points).\nStopping condition 1 reached. All data points have the same target value.\n--------------------------------------------------------------------\nSubtree, depth = 1 (34629 data points).\ngrade_D\n--------------------------------------------------------------------\nSubtree, depth = 2 (28778 data points).\ngrade_E\n--------------------------------------------------------------------\nSubtree, depth = 3 (27187 data points).\ngrade_C\n--------------------------------------------------------------------\nSubtree, depth = 4 (18252 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 4 (8935 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 3 (1591 data points).\ngrade_A\n--------------------------------------------------------------------\nSubtree, depth = 4 (1591 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 4 (0 data points).\nStopping condition 1 reached. All data points have the same target value.\n--------------------------------------------------------------------\nSubtree, depth = 2 (5851 data points).\ngrade_A\n--------------------------------------------------------------------\nSubtree, depth = 3 (5851 data points).\ngrade_B\n--------------------------------------------------------------------\nSubtree, depth = 4 (5851 data points).\nEarly stopping condition 1 reached. Reached maximum depth.\n--------------------------------------------------------------------\nSubtree, depth = 4 (0 data points).\nStopping condition 1 reached. All data points have the same target value.\n--------------------------------------------------------------------\nSubtree, depth = 3 (0 data points).\nStopping condition 1 reached. All data points have the same target value.\n"
    }
   ],
   "source": [
    "small_decision_tree = generate_tree(loans_data, features, 'safe_loans', max_depth = 4, \n",
    "                                        min_node_size = 10, min_error_reduction=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, x):\n",
    "    if tree['is_leaf']:\n",
    "        return tree['prediction']\n",
    "    else:\n",
    "        # print(tree['splitting_feature'])\n",
    "        splitting_feature_value = x[tree['splitting_feature']]\n",
    "        if splitting_feature_value == 0:\n",
    "            # print(0)\n",
    "            return classify(tree['left'], x)\n",
    "        else:\n",
    "            # print(1)\n",
    "            return classify(tree['right'], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_data['prediction'] = 99\n",
    "for i in np.arange(len(loans_data)):\n",
    "    loans_data['prediction'][i] = classify(small_decision_tree, loans_data.iloc[i,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-1    27788\n 1    18512\nName: prediction, dtype: int64"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "loans_data['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.609805615550756"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "(loans_data['prediction'] == loans_data['safe_loans']).sum()/len(loans_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "1. The recursion aspect of building tree is critical.   \n",
    "2. The above example examines only categorical features for simplicity. \n",
    "3. Remember the three stopping criteria. Always have code for edge cases (like when all target values at start belong to same class)\n",
    "4. The early stopping can affect the overfitting scenarios. That can be checked with low, medium and high values for each criteria. The model complexity can be checked at number of leave nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}