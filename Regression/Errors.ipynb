{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Different Measures of error\n",
    "1. Training error :             \n",
    "Loss in training set. Training error will lead to good predictions unless training data includes everything you might ever see\n",
    "2. Generalization error :           \n",
    "What we really want. Ideal out of model error when we have the entire population data. But we dont have all of them.        \n",
    "As shown in fig below, at each X there exists a possible distribution of values which we might not know. So ideal true relation is shown as red line, best case mean expectation covering all along X mean values.\n",
    "\n",
    "![title](Images\\Generalization.PNG)\n",
    "3. Testing error:       \n",
    "What we can actually compute.         \n",
    "    \n",
    "\n",
    "## 3 Sources of error\n",
    "1. Bias (reducible): \n",
    "Approximating the true relationship with some function. Inability to capture. Difference betw true function and avg function. Avg of multiple sub-samples predictions. In fig below, we considered a constant value for all sub-samples. So it is not flexible enough to capture the true relationship. Hence, low complexity -> high bias\n",
    "The difference between the avg value of model to the true functional model.\n",
    "$$ Bias \\hat f(x) = E[ \\hat f(x)] - f(x) $$\n",
    "![title](Images\\Bias.PNG)\n",
    "![title](Images\\Bias_Variance.PNG)              \n",
    "2. Variance (reducible)         \n",
    "How much do specific fits vary from expected fits. Low complexity model -> low variance. Predictions shouldnt be very sensitive to data samples.            \n",
    "In ex below, if we take avg of all these sub-sample complex models, the avg model looks so good at capturing true relationship(low bias), but at extent of high variance. bcos you can see at every x's the amount of variation with change of data is huge.    \n",
    "The variance in itself, all the models built. How much the different f(x) (trained on diff samples) were from each other\n",
    "$$ Variance \\hat f(x) = E[ \\hat f(x) - E[\\hat f(x)])^2] $$        \n",
    "![title](Images\\Variance.PNG)\n",
    "\n",
    "3. Noise (irreducible)          \n",
    "Data inherently noisy. At specific x, the noise can vary, that is referred as variance in noise. No control bcos it doesnt change with better model.        \n",
    "![title](Images\\irreducibleError.PNG)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}